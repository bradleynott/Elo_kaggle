{"cells":[{"metadata":{},"cell_type":"markdown","source":"# MIDS w207 - Final Project\n## Elo Merchant Category Recommendation Kaggle Challenge\n\n### Team 3\n- Vinicio De Sola\n- Kevin Hanna\n- Pri Nonis\n- Bradley Nott"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy   as np # linear algebra\nimport pandas  as pd # data processing\nimport os.path as op # file system access\nimport os      as os\nimport gc      as gc\nimport time    as ti","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def root_mean_squared_error(y_true, y_pred) :\n    return np.sqrt(((y_pred - y_true) ** 2).mean())\n\ndef mean_squared_error(y_true, y_pred) :\n    return ((y_pred - y_true) ** 2).mean()\n\ndef setup_environment() :\n    globals()['csv_base'] = '../input'  if 'working' in os.getcwd() else './input'\n    globals()['pkl_base'] = '../pickle' if 'working' in os.getcwd() else './pickle'\n    \n    os.makedirs(csv_base, exist_ok = True)\n    os.makedirs(pkl_base, exist_ok = True)\n    \n    pd.set_option('display.max_rows', 500)\n    pd.set_option('display.max_columns', 500)\n    pd.set_option('display.width', 1000)\n    \n    import warnings\n    warnings.filterwarnings('ignore')\n\nsetup_environment()","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Loading and Cleanup"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"def compress(df, verbose = True) :\n    smu = df.memory_usage().sum() / 1024**2 / 8\n    con = {'f' : {                                   np.finfo(np.float16).max : np.float16, np.finfo(np.float32).max : np.float32, np.finfo(np.float64).max : np.float64},\n           'u' : {np.iinfo(np.uint8).max : np.uint8, np.iinfo(np.uint16).max  : np.uint16,  np.iinfo(np.uint32).max  : np.uint32,  np.iinfo(np.uint64).max  : np.uint64},\n           'i' : {np.iinfo(np.int8).max  : np.int8,  np.iinfo(np.int16).max   : np.int16,   np.iinfo(np.int32).max   : np.int32,   np.iinfo(np.int64).max   : np.int64}}\n\n    for c in df.columns :\n        if  con.get(df[c].dtype.kind) :\n            df[c] = df[c].astype(con[df[c].dtype.kind].get(min((n for n in con[df[c].dtype.kind].keys() if n > max(df[c].max(), abs(df[c].min()))))))\n\n    emu = df.memory_usage().sum() / 1024**2 / 8\n\n    if  verbose :\n        print(f'Memory Use Decreased to {emu:5.2f} MB [{100 * (smu - emu) / emu:5.1f}% Reduction]')\n\n    return df, 100 * (smu - emu) / emu\n\ndef read(csv_path, dates = [], brize = [], dummy = [], delna = False, index = None, regen = False) :\n    pkl_path = op.join(pkl_base, csv_path).replace('.csv', '.pkl')\n    csv_path = op.join(csv_base, csv_path)\n    srt_time = ti.time()\n    \n    if  op.exists(pkl_path) and not regen :\n        df       = pd.read_pickle(pkl_path)\n        csv_path = pkl_path\n        rp       = 0.0\n    else                    :\n        df = pd.read_csv(csv_path, parse_dates = dates, memory_map = True)\n        if  index :\n            df = df.set_index(index)\n        df, rp = compress(df, verbose = False)\n\n        df.to_pickle(pkl_path)\n\n    print(f'Loading : {op.basename(csv_path):>29} in {ti.time()-srt_time:5.1f} Seconds, Shape is {str(df.shape):>14}, Memory Usage is {df.memory_usage().sum() / 1024**2 / 8:6.2f} MB [Reduction of {rp:5.1f} %].')\n\n    return df\n\ndef load() :\n    data           = {}\n    data['train' ] = read('train.csv', dates = ['first_active_month'], index = 'card_id', regen = True)\n    data['test'  ] = read('test.csv',  dates = ['first_active_month'], index = 'card_id', regen = True)\n  # data['mercs' ] = read('merchants.csv', index = 'merchant_id')\n    data['tx_new'] = read('new_merchant_transactions.csv', dates = ['purchase_date'])\n    data['tx_old'] = read('historical_transactions.csv',   dates = ['purchase_date'])\n    data['target'] = data['train'].pop('target')\n    print(f'\\nLoading : Done.')\n\n    return data\n\ndef clean(data) :\n  # replace missing first active month\n    data['test'].loc['C_ID_c27b4f80f7', 'first_active_month'] = data['test']['first_active_month'].min()\n    \n    return data","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = clean(load())","execution_count":7,"outputs":[{"output_type":"stream","text":"Loading :                     train.csv in   0.7 Seconds, Shape is    (201917, 5), Memory Usage is   0.51 MB [Reduction of 128.6 %].\nLoading :                      test.csv in   0.3 Seconds, Shape is    (123623, 4), Memory Usage is   0.28 MB [Reduction of 110.5 %].\nLoading : new_merchant_transactions.csv in   8.9 Seconds, Shape is  (1963031, 14), Memory Usage is  14.27 MB [Reduction of  83.6 %].\nLoading :   historical_transactions.csv in 112.7 Seconds, Shape is (29112361, 14), Memory Usage is 218.64 MB [Reduction of  77.8 %].\n\nLoading : Done.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"def draft(data) :\n\n    np.random.seed(0)\n    \n    plan = {}\n    \n    plan['scorer'        ] = root_mean_squared_error\n    plan['baseline_model'] = None\n    plan['best_model'    ] = None\n    plan['baseline_score'] =   0.0\n    plan['best_score'    ] = 100.0\n    plan['baseline_feats'] = []\n    plan['best_feats'    ] = []\n\n    plan['train_size'] = len(data['train' ])\n    plan['train_pcnt'] = 0.8\n    plan['train_mask'] = np.random.rand(plan['train_size']) < plan['train_pcnt']\n    plan['devel_mask'] =               ~plan['train_mask']\n\n    plan['target' ] = data['target']\n    plan['y_train'] = data['target'][plan['train_mask']]\n    plan['y_devel'] = data['target'][plan['devel_mask']]\n\n    plan['first_active_month_max'] = max(data['train' ].first_active_month.max(),\n                                         data['test'  ].first_active_month.max())\n    plan['purchase_date_max'     ] = max(data['tx_old'].purchase_date.max(),\n                                         data['tx_new'].purchase_date.max())\n    plan['purchase_date_ref'     ] =     data['tx_old'].purchase_date.max()\n\n    return plan","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plan = draft(data)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def engineer_transactions(tf, prefix) :\n\n  # binarize boolean Y/N flag variables\n    tf['category_1'     ] = tf['category_1'     ].eq('Y').mul(1)\n    tf['authorized_flag'] = tf['authorized_flag'].eq('Y').mul(1)\n\n  # convert categorical variables to dummy/indicator, preserve original categorical variable\n    tf = pd.concat([tf, pd.get_dummies(tf[['category_2', 'category_3']],\n                                columns = ['category_2', 'category_3'])], axis = 1)\n\n  # recover purchase history by denormolizing\n    tf['month_diff'    ] = (plan['purchase_date_ref'] - tf['purchase_date']) // np.timedelta64(1, 'M') \\\n                         + (                            tf['month_lag'    ])\n\n  # extract purchase_month from date\n    tf['purchase_month'] = tf['purchase_date'].dt.month\n\n  # convert datetime to numerical\n    tf['purchase_ndate'] = tf['purchase_date'].astype(np.int64) * 1e-9\n\n    return tf\n    \ndef engineer_transactions_aggregated(tf, prefix, regen = False) :\n\n    pkl_path = op.join(pkl_base, f'engineered_{prefix}_transactions_aggregated.pkl')\n    srt_time = ti.time()\n    \n    if  op.exists(pkl_path) and not regen :\n\n        df = pd.read_pickle(pkl_path)\n        \n    else :\n\n        tf = engineer_transactions(tf, tf)\n\n      # ─────────────────────────────────────────────────────────────────────────────────────────────────────────────\n      # aggregate transactions per card\n      # ─────────────────────────────────────────────────────────────────────────────────────────────────────────────\n\n        aggregations = \\\n        {\n            'category_1'           : ['mean', 'sum'],\n\n            'category_2_1.0'       : ['mean'],\n            'category_2_2.0'       : ['mean'],\n            'category_2_3.0'       : ['mean'],\n            'category_2_4.0'       : ['mean'],\n            'category_2_5.0'       : ['mean'],\n            'category_3_A'         : ['mean'],\n            'category_3_B'         : ['mean'],\n            'category_3_C'         : ['mean'],\n\n            'merchant_id'          : ['nunique'],\n            'merchant_category_id' : ['nunique'],\n            'state_id'             : ['nunique'],\n            'city_id'              : ['nunique'],\n            'subsector_id'         : ['nunique'],\n\n            'purchase_amount'      : ['mean', 'sum', 'max', 'min', 'std'],\n            'installments'         : ['mean', 'sum', 'max', 'min', 'std'],\n            'purchase_month'       : ['mean',        'max', 'min', 'std'],\n            'purchase_ndate'       : [np.ptp,        'max', 'min'       ],\n            'month_lag'            : ['mean',        'max', 'min', 'std'],\n            'month_diff'           : ['mean'                            ]\n        }\n\n        aggregations_kev = \\\n        {\n            'purchase_amount'      : ['sum', 'mean', 'median', 'min', 'max', 'std'],\n            'subsector_id'         : ['nunique'],\n            'merchant_category_id' : ['nunique'],\n            'merchant_id'          : ['nunique'],\n            'installments'         : ['sum', 'mean'],\n            'city_id'              : ['nunique'],\n            'state_id'             : ['nunique'], \n            'category_1'           : ['sum'],\n            'category_2_1.0'       : ['sum'],\n            'category_2_2.0'       : ['sum'],\n            'category_2_3.0'       : ['sum'],\n            'category_2_4.0'       : ['sum'],\n            'category_2_5.0'       : ['sum'],\n            'category_3_A'         : ['sum'],\n            'category_3_B'         : ['sum'],\n            'category_3_C'         : ['sum'],\n\n            'month_lag'           : ['mean', 'min', 'max', 'std'],\n            'authorized_flag'     : ['sum'],\n            'month_diff'          : ['mean', 'min', 'max', 'std'],\n            'purchase_date'       : [np.ptp, 'min', 'max']\n        }\n\n      # add aggregations\n        df = tf.groupby(['card_id']).agg(aggregations)\n        df.columns = ['_'.join((prefix,) + c) for c in df.columns.values]\n        df.reset_index(inplace = True)\n       \n      # add aggregated transaction count\n        tc = tf.groupby('card_id').size().reset_index(name = f'{prefix}_transaction_count')\n        df = pd.merge(tc, df, on = 'card_id', how = 'left')\n\n        df.to_pickle(pkl_path)\n    \n    print(f'Engineering : {prefix:>5} Transactions in {ti.time()-srt_time:5.1f} Seconds.')\n    \n    return df","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def engineer_cards(df, aggs, plan, prefix, regen = False) :\n\n    pkl_path = op.join(pkl_base, f'engineered_{prefix}_cards.pkl')\n    srt_time = ti.time()\n    \n    if  op.exists(pkl_path) and not regen :\n\n        df = pd.read_pickle(pkl_path)\n\n    else :\n    \n      # convert categorical variables to dummy/indicator, preserve original categorical variable\n        df = pd.concat([df, pd.get_dummies(df[['feature_1', 'feature_2']],\n                                    columns = ['feature_1', 'feature_2'])], axis = 1)\n\n      # normalized active days of card from first date the shopper made a purchase through Elo\n        df['active_days'] = (plan['first_active_month_max'] - df['first_active_month']).dt.days\n\n        for agg in aggs :\n            df = pd.merge( df, aggs[agg], on = 'card_id', how = 'left')\n\n        df.to_pickle(pkl_path)\n            \n    print(f'Engineering : {prefix:>5} Cards        in {ti.time()-srt_time:5.1f} Seconds.')\n        \n    return df","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def engineer(data, plan, delete = False) :\n\n  # extract approved old transactions\n    data['tx_app'] = data['tx_old'][data['tx_old']['authorized_flag'] == 'Y']\n\n  # aggregate transaction features\n    aggs           = {}\n    aggs['tx_new'] = engineer_transactions_aggregated(data['tx_new'], prefix = 'new')\n    aggs['tx_old'] = engineer_transactions_aggregated(data['tx_old'], prefix = 'old')\n    aggs['tx_app'] = engineer_transactions_aggregated(data['tx_app'], prefix = 'app')\n\n  # join aggregated features to train and test sets\n    feat           = {}\n    feat['train' ] = engineer_cards(data['train'], aggs, plan, prefix = 'train', regen = True)\n    feat['test'  ] = engineer_cards(data['test' ], aggs, plan, prefix = 'test' , regen = True)\n  \n    if  delete :\n        del aggs\n        del data\n        del globals()['data']\n        d = gc.collect()\n    \n    print(f'\\nEngineering : Done.')\n\n    return feat","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat = engineer(data, plan)","execution_count":13,"outputs":[{"output_type":"stream","text":"Engineering :   new Transactions in  50.6 Seconds.\nEngineering :   old Transactions in 218.4 Seconds.\nEngineering :   app Transactions in 202.0 Seconds.\nEngineering : train Cards        in   2.5 Seconds.\nEngineering :  test Cards        in   1.9 Seconds.\n\nEngineering : Done.\n","name":"stdout"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"feat['train'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print('\\n'.join(sorted(feat['train'].columns.values)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Baseline - Linear Regression Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def select(feat, include = [], exclude = []) :\n    columns = feat['train'].columns.values\n    \n    if  include :\n        columns = [c for c in columns if c     in include]\n    if  exclude :\n        columns = [c for c in columns if c not in exclude]\n        \n    return columns\n\ndef prep(plan, feat, include = [], exclude = []) :\n    play            = {}\n    play['feats'  ] = select(feat, include, exclude)\n\n    play['target' ] = plan['target']                          # full train labels\n    play['train'  ] = feat['train' ][play['feats']].fillna(0) # full train data\n    play['test'   ] = feat['test'  ][play['feats']].fillna(0) # full test  data\n\n    play['x_train'] = feat['train' ][play['feats']][plan['train_mask']].fillna(0) # train data   split 80%\n    play['y_train'] = plan['target'][plan['train_mask']]                          # train labels split 80%\n\n    play['x_devel'] = feat['train' ][play['feats']][plan['devel_mask']].fillna(0) # train data   split 20%\n    play['y_devel'] = plan['target'][plan['devel_mask']]                          # train labels split 80%\n\n    play['x_test' ] = feat['test'  ][play['feats'  ]].fillna(0)\n    \n    return play\n\ndef grade(plan, kind, y_pred, y_test, tag = '', baseline = False) :\n    if  baseline :\n        plan[    'best_score'] = \\\n        plan['baseline_score'] = plan['scorer'](plan['y_devel'], y_pred)\n        plan[    'best_ytest'] = \\\n        plan['baseline_ytest'] = y_test\n        tag                   += '⭕'\n\n    score   =  plan['scorer'](plan['y_devel'], y_pred)\n    improve = (plan['baseline_score'] - score) / plan['baseline_score'] * 100\n\n    if  score <= plan['best_score'] and not baseline :\n        plan['best_ytest'] = y_test\n        plan['best_score'] = score\n        tag               += '⭐'\n\n    print(f'{kind:<17} : Score is {score:6.3f} [{improve:+6.3f}%]' +\n         (f' {tag}' if tag else ''))\n\n    return plan","execution_count":53,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def regression(plan, play, opts = {}, baseline = False) :\n    kind    = 'Linear Regression'\n\n    from sklearn.linear_model  import LinearRegression\n\n    model   = LinearRegression() \\\n                .fit(play['x_train'], play['y_train'])\n\n    return grade(plan, kind, model.predict(play['x_devel']), model.predict(play['x_test']), baseline = baseline)","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def regression_play(plan, feat) :\n    plan = regression(plan, play = prep(plan, feat, include = ['feature_1', 'feature_2', 'feature_3'               ]), baseline = True ) # base features in train          - baseline\n    plan = regression(plan, play = prep(plan, feat, include = ['old_purchase_amount_sum', 'new_purchase_amount_sum']), baseline = False) # old vs new purchase amounts     - experiment\n    plan = regression(plan, play = prep(plan, feat, exclude = ['card_id', 'first_active_month'                     ]), baseline = False) # all numeric engineered features - kitchen sink\n\n    return plan\n\nplan = regression_play(plan, feat)","execution_count":35,"outputs":[{"output_type":"stream","text":"Linear Regression : Score is  3.777 [+0.000%] ⭕\nLinear Regression : Score is  3.789 [-0.306%]\nLinear Regression : Score is  3.799 [-0.586%]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Lasso Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def lasso(plan, play, opts) :\n    kind    = 'Linear Lasso'\n\n    from sklearn.model_selection import GridSearchCV\n    from sklearn.model_selection import KFold\n    from sklearn.linear_model    import Lasso\n\n    params  = [{'alpha' : opts}]\n    folds   = 5\n\n    grid    = GridSearchCV(Lasso(random_state = 0), params, cv = folds, scoring = 'neg_mean_squared_error') \\\n                .fit(play['x_train'], play['y_train'])\n    model   = grid.best_estimator_\n\n    return grade(plan, kind, model.predict(play['x_devel']), model.predict(play['x_test']), tag = f'(Alpha = {grid.best_estimator_.alpha:8.5f}) ')","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lasso_play(plan, feat) :\n    plan = lasso(plan, play = prep(plan, feat, include = ['feature_1', 'feature_2', 'feature_3'               ]), opts = [0.00001, 0.001, 0.5, 10])\n    plan = lasso(plan, play = prep(plan, feat, include = ['old_purchase_amount_sum', 'new_purchase_amount_sum']), opts = np.logspace(-4, -0.5, 30))\n  # plan = lasso(plan, play = prep(plan, feat, exclude = ['card_id'                                           ]), opts = [0.001]                  )\n\n    return plan\n\nplan = lasso_play(plan, feat)","execution_count":37,"outputs":[{"output_type":"stream","text":"Linear Lasso      : Score is  3.777 [-0.000%] (Alpha =  0.00100) \nLinear Lasso      : Score is  3.789 [-0.307%] (Alpha =  0.00010) \n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Light Gradient Boost\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def lgm(plan, play, opts) :\n    kind = 'Light Gradient Boost'\n\n    from sklearn.model_selection import KFold\n    from lightgbm                import Dataset, train\n    \n    rmse    = 0\n    folds   = KFold(n_splits = opts['n_splits'], shuffle = opts['shuffle'], random_state = opts['r_state'])\n    y_train = np.zeros(len(play['train']))\n    y_test  = np.zeros(len(play['test' ]))\n\n    for f, (tin, vin) in enumerate(folds.split(play['train'].values, play['target'].values)) :\n        \n        print(f'Fold {f}')\n        \n        tdf = Dataset(play['train'].iloc[tin], label = play['target'].iloc[tin], categorical_feature = ['feature_2', 'feature_3']) # train data fold\n        vdf = Dataset(play['train'].iloc[vin], label = play['target'].iloc[vin], categorical_feature = ['feature_2', 'feature_3']) # valid data fold\n    \n        clf = train(params = opts['params'],\n                    train_set = tdf,\n                    num_boost_round = opts['rounds'],\n                    valid_sets = [tdf, vdf],\n                    verbose_eval = opts['v_eval'],\n                    early_stopping_rounds = opts['e_stop'])\n\n        y_train[vin] = clf.predict(play['train'].iloc[vin], num_iteration = clf.best_iteration)\n        y_test      += clf.predict(play['test' ],           num_iteration = clf.best_iteration) / folds.n_splits\n      # rmse        += mean_squared_error(play['target'].iloc[vin], y_pred) ** 0.5\n\n    y_pred = y_train[plan['y_devel']]\n\n    print(f\"CV Score : {mean_squared_error(y_train, play['target']) ** 0.5:<8.5f}\")\n\n    return grade(plan, kind, y_pred, y_test)","execution_count":59,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lgm_play(plan, feat) :\n\n    opts_elo = \\\n    {   'n_splits': 5,\n        'shuffle' : True,\n        'r_state' : 15,\n        'rounds'  : 10000,\n        'e_stop'  : 200,\n        'v_eval'  : 0,\n        'params'  :\n         {  'num_leaves'       : 111,\n            'min_data_in_leaf' : 149, \n            'objective'        :'regression',\n            'max_depth'        : 9,\n            'learning_rate'    : 0.005,\n            'boosting'         : 'gbdt',\n            'feature_fraction' : 0.7522,\n            'bagging_freq'     : 1,\n            'bagging_fraction' : 0.7083 ,\n            'bagging_seed'     : 11,\n            'metric'           : 'rmse',\n            'lambda_l1'        : 0.2634,\n            'random_state'     : 133,\n            'verbosity'        : -1\n         }\n    }\n\n    opts_kev = \\\n    {   'n_splits': 10,\n        'shuffle' : True,\n        'r_state' : 15,\n        'rounds'  : 5000,\n        'e_stop'  : 100,\n        'v_eval'  : 0,\n        'params'  :\n        {   'num_leaves' : 125,\n            'num_trees'  : 150,\n            'objective'  : 'regression',\n            'metric'     : 'rmse'\n        }\n    }\n    \n    plan = lgm(plan, play = prep(plan, feat, exclude = ['card_id', 'first_active_month']), opts = opts_elo)\n    plan = lgm(plan, play = prep(plan, feat, exclude = ['card_id', 'first_active_month']), opts = opts_kev)\n\n    return plan\n\nplan = lgm_play(plan, feat)","execution_count":null,"outputs":[{"output_type":"stream","text":"Fold 0\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# XGBoost"},{"metadata":{"trusted":false},"cell_type":"code","source":"def xgboost(plan, feat, features, params = {}) :\n    kind    = 'XGBoost'\n    x_train,\\\n    x_devel,\\\n    x_test  = prep(plan, feat, features)\n\n    y_pred  = np.ones(len(x_devel)) * -0.3928\n    y_test  = np.ones(len(x_test )) * -0.3928\n\n    return grade(plan, kind, y_pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def xgboost_play(plan, feat) :\n    plan = xgboost(plan, feat, features = ['feature_1', 'feature_2', 'feature_3'               ])\n    \n    return plan\n\nplan = xgboost_play(plan, feat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plan['y_devel'].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Neural Network"},{"metadata":{"trusted":false},"cell_type":"code","source":"def neural(plan, feat, features, params = {}) :\n    kind    = 'Neural Network'\n    x_train,\\\n    x_devel,\\\n    x_test  = prep(plan, feat, features)\n\n    y_pred  = np.zeros(len(x_devel))\n    y_test  = np.zeros(len(x_test ))\n\n    return grade(plan, kind, y_pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def neural_play(plan, feat) :\n    plan = neural(plan, feat, features = ['feature_1', 'feature_2', 'feature_3'               ])\n    \n    return plan\n\nplan = neural_play(plan, feat)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make Submission"},{"metadata":{"trusted":false},"cell_type":"code","source":"def submit(plan, feat) :\n\n    model  = plan['best_model']\n    feats  = plan['best_feats']\n    score  = plan['best_score']\n\n    x_test = feat['test'][feats]\n    y_pred = model.predict(x_test)\n    \n    submission = pd.DataFrame({ 'card_id' : feat['test']['card_id'].values,\n                                'target'  : y_pred })\n    \n    display(submission.head())\n    \n    submission.to_csv('submission.csv', index = False)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit(plan, feat)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}